import streamlit as st
import pandas as pd
import torch
from transformers import LayoutLMTokenizerFast, LayoutLMForTokenClassification
from PIL import Image, ImageDraw, ImageFont
import easyocr
import numpy as np
import google.generativeai as genai
import plotly.express as px

# --- Cáº¤U HÃŒNH VÃ€ Táº¢I TÃ€I NGUYÃŠN ---

# Cáº¥u hÃ¬nh API Key cho Gemini (Láº¥y tá»« Google AI Studio)
# Báº N NÃŠN DÃ™NG st.secrets Äá»‚ Báº¢O Máº¬T API KEY KHI DEPLOY
# VÃ­ dá»¥: genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
# á» Ä‘Ã¢y, Ä‘á»ƒ cháº¡y local, báº¡n cÃ³ thá»ƒ dÃ¡n key trá»±c tiáº¿p hoáº·c dÃ¹ng secrets.toml
try:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
    GEMINI_AVAILABLE = True
except (FileNotFoundError, KeyError):
    GEMINI_AVAILABLE = False
    st.sidebar.warning("KhÃ´ng tÃ¬m tháº¥y Google API Key. TÃ­nh nÄƒng Chatbot sáº½ bá»‹ vÃ´ hiá»‡u hÃ³a.")


MODEL_PATH = "./layoutlm-sroie-finetuned-modern"
DATA_FILE = "extracted_data.csv" # File Ä‘á»ƒ lÆ°u trá»¯ dá»¯ liá»‡u

label2color = {
    'COMPANY': 'blue',
    'DATE': 'green',
    'ADDRESS': 'orange',
    'TOTAL': 'red'
}

# Sá»­ dá»¥ng cache cá»§a Streamlit Ä‘á»ƒ chá»‰ táº£i model vÃ  OCR reader má»™t láº§n
@st.cache_resource
def load_resources():
    tokenizer = LayoutLMTokenizerFast.from_pretrained(MODEL_PATH)
    model = LayoutLMForTokenClassification.from_pretrained(MODEL_PATH)
    reader = easyocr.Reader(['en'], gpu=False)

    id2label = {0: "S-COMPANY", 1: "S-DATE", 2: "S-ADDRESS", 3: "S-TOTAL", 4: "O"}
    label2id = {label: id for id, label in id2label.items()}
    
    model.config.id2label = id2label
    model.config.label2id = label2id
    
    return tokenizer, model, reader

# Táº£i tÃ i nguyÃªn
tokenizer, model, reader = load_resources()
LABELS = [label.replace("S-", "") for label in model.config.id2label.values() if label != "O"]


# --- KHá»I Táº O SESSION STATE ---
# Session state Ä‘á»ƒ lÆ°u dá»¯ liá»‡u giá»¯a cÃ¡c láº§n tÆ°Æ¡ng tÃ¡c
if 'data_df' not in st.session_state:
    try:
        # Thá»­ táº£i dá»¯ liá»‡u Ä‘Ã£ lÆ°u náº¿u cÃ³
        st.session_state.data_df = pd.read_csv(DATA_FILE)
    except FileNotFoundError:
        # Náº¿u khÃ´ng cÃ³, táº¡o DataFrame rá»—ng
        st.session_state.data_df = pd.DataFrame(columns=LABELS + ["CATEGORY"])

if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []


# --- CÃC HÃ€M Xá»¬ LÃ (GIá»® NGUYÃŠN Tá»ª PHIÃŠN Báº¢N TRÆ¯á»šC) ---

def normalize_box(box, width, height):
    return [
        int(1000 * (box[0] / width)), int(1000 * (box[1] / height)),
        int(1000 * (box[2] / width)), int(1000 * (box[3] / height)),
    ]

def process_image(image):
    width, height = image.size
    ocr_results = reader.readtext(np.array(image))
    if not ocr_results: return None, None

    words = [res[1] for res in ocr_results]
    unnormalized_boxes = [[int(p) for p in box[0]] + [int(p) for p in box[2]] for box, _, _ in ocr_results]
    normalized_boxes = [normalize_box(box, width, height) for box in unnormalized_boxes]

    tokenized_inputs = tokenizer(words, padding="max_length", max_length=512, truncation=True, is_split_into_words=True, return_tensors="pt")
    word_ids = tokenized_inputs.word_ids()

    bbox_list = [normalized_boxes[word_idx] if word_idx is not None else [0,0,0,0] for word_idx in word_ids]
    bbox = torch.tensor(bbox_list).unsqueeze(0)

    model.eval()
    with torch.no_grad():
        outputs = model(input_ids=tokenized_inputs['input_ids'], bbox=bbox, attention_mask=tokenized_inputs['attention_mask'], token_type_ids=tokenized_inputs['token_type_ids'])
    
    predictions = outputs.logits.argmax(-1).squeeze().tolist()
    token_labels = [model.config.id2label[pred] for pred in predictions]

    word_level_predictions = []
    previous_word_idx = None
    for i, word_idx in enumerate(word_ids):
        if word_idx is None or word_idx == previous_word_idx: continue
        label = token_labels[i].replace("S-", "")
        word_level_predictions.append({"word": words[word_idx], "label": label, "box": unnormalized_boxes[word_idx]})
        previous_word_idx = word_idx

    extracted_data = {label: [] for label in LABELS}
    for item in word_level_predictions:
        if item["label"] in LABELS:
            extracted_data[item["label"]].append(item["word"])

    for label in LABELS:
        extracted_data[label] = ' '.join(extracted_data[label])

    return extracted_data, word_level_predictions

def draw_predictions(image, predictions):
    drawn_image = image.copy()
    draw = ImageDraw.Draw(drawn_image)
    try: font = ImageFont.truetype("arial.ttf", size=15)
    except IOError: font = ImageFont.load_default()

    for item in predictions:
        if item["label"] in label2color:
            draw.rectangle(item["box"], outline=label2color[item["label"]], width=2)
            draw.text((item["box"][0], item["box"][1] - 15), item["label"], fill=label2color[item["label"]], font=font)
    return drawn_image


# --- Äá»ŠNH NGHÄ¨A CÃC TRANG (SECTIONS) ---

def page_home():
    st.header("Trang chá»§: Táº£i lÃªn vÃ  Xá»­ lÃ½ HÃ³a Ä‘Æ¡n")
    st.write("Chá»n má»™t hoáº·c nhiá»u file áº£nh hÃ³a Ä‘Æ¡n Ä‘á»ƒ trÃ­ch xuáº¥t thÃ´ng tin.")
    
    uploaded_files = st.file_uploader(
        "Chá»n file áº£nh", 
        type=["jpg", "jpeg", "png"], 
        accept_multiple_files=True
    )

    if uploaded_files:
        new_data = []
        for uploaded_file in uploaded_files:
            st.markdown(f"---")
            st.subheader(f"Káº¿t quáº£ cho: `{uploaded_file.name}`")
            image = Image.open(uploaded_file).convert("RGB")
            
            col1, col2 = st.columns(2)
            col1.image(image, caption="áº¢nh Gá»‘c", use_container_width=True)

            with st.spinner("Äang trÃ­ch xuáº¥t..."):
                extracted_data, word_level_predictions = process_image(image)
            
            if extracted_data:
                annotated_image = draw_predictions(image, word_level_predictions)
                col2.image(annotated_image, caption="Káº¿t quáº£ TrÃ­ch xuáº¥t", use_container_width=True)
                
                st.write("ThÃ´ng tin trÃ­ch xuáº¥t:")
                st.json(extracted_data)
                
                # YÃªu cáº§u ngÆ°á»i dÃ¹ng gÃ¡n danh má»¥c
                category_options = ["Táº¡p hÃ³a", "Tiá»‡n Ã­ch", "Du lá»‹ch", "Váº­t tÆ° VÄƒn phÃ²ng", "Tiá»n thuÃª nhÃ ", "KhÃ¡c"]
                category = st.selectbox(f"Chá»n danh má»¥c cho hÃ³a Ä‘Æ¡n '{uploaded_file.name}':", category_options, key=uploaded_file.name)
                
                extracted_data["CATEGORY"] = category
                new_data.append(extracted_data)
            else:
                col2.error("KhÃ´ng tÃ¬m tháº¥y vÄƒn báº£n trong áº£nh nÃ y.")
        
        if st.button("LÆ°u táº¥t cáº£ káº¿t quáº£ Ä‘Ã£ trÃ­ch xuáº¥t"):
            new_df = pd.DataFrame(new_data)
            st.session_state.data_df = pd.concat([st.session_state.data_df, new_df], ignore_index=True)
            st.session_state.data_df.to_csv(DATA_FILE, index=False)
            st.success(f"ÄÃ£ lÆ°u thÃ nh cÃ´ng {len(new_data)} hÃ³a Ä‘Æ¡n vÃ o `{DATA_FILE}`!")
            st.balloons()


def page_data_storage():
    st.header("Kho Dá»¯ liá»‡u HÃ³a Ä‘Æ¡n")
    st.write("DÆ°á»›i Ä‘Ã¢y lÃ  toÃ n bá»™ dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c trÃ­ch xuáº¥t vÃ  lÆ°u trá»¯.")
    if not st.session_state.data_df.empty:
        st.dataframe(st.session_state.data_df)
        
        # Chuyá»ƒn Ä‘á»•i DataFrame thÃ nh CSV Ä‘á»ƒ ngÆ°á»i dÃ¹ng cÃ³ thá»ƒ táº£i vá»
        csv = st.session_state.data_df.to_csv(index=False).encode('utf-8')
        st.download_button(
           "Táº£i vá» file CSV",
           csv,
           "hoa_don_da_trich_xuat.csv",
           "text/csv",
           key='download-csv'
        )
    else:
        st.info("ChÆ°a cÃ³ dá»¯ liá»‡u nÃ o Ä‘Æ°á»£c lÆ°u. Vui lÃ²ng táº£i lÃªn hÃ³a Ä‘Æ¡n á»Ÿ trang chá»§.")

def page_visualization():
    st.header("Trá»±c quan hÃ³a Chi tiÃªu")
    st.write("Xem cÃ¡c biá»ƒu Ä‘á»“ thá»‘ng kÃª dá»±a trÃªn dá»¯ liá»‡u hÃ³a Ä‘Æ¡n cá»§a báº¡n.")
    
    df = st.session_state.data_df.copy()
    if df.empty:
        st.warning("KhÃ´ng cÃ³ dá»¯ liá»‡u Ä‘á»ƒ váº½ biá»ƒu Ä‘á»“.")
        return

    # --- BÆ¯á»šC LÃ€M Sáº CH VÃ€ CHUYá»‚N Äá»”I CHUNG ---
    df['TOTAL'] = df['TOTAL'].astype(str).str.replace(r'[^\d.]', '', regex=True)
    df['TOTAL'] = pd.to_numeric(df['TOTAL'], errors='coerce')
    df['DATE'] = pd.to_datetime(df['DATE'], errors='coerce')

    # â­ï¸ Sá»¬A Lá»–I: XÃ³a dÃ²ng dropna chung á»Ÿ Ä‘Ã¢y
    # df.dropna(subset=['TOTAL', 'DATE', 'CATEGORY'], inplace=True) 

    st.subheader("Chá»n loáº¡i biá»ƒu Ä‘á»“ báº¡n muá»‘n xem:")
    
    chart_type = st.radio(
        "Loáº¡i biá»ƒu Ä‘á»“:",
        ("Chi tiÃªu theo danh má»¥c (Biá»ƒu Ä‘á»“ trÃ²n)", 
         "Chi tiÃªu theo thá»i gian (Biá»ƒu Ä‘á»“ Ä‘Æ°á»ng)",
         "Top 5 nhÃ  cung cáº¥p chi tiÃªu nhiá»u nháº¥t (Biá»ƒu Ä‘á»“ cá»™t)")
    )
    
    if chart_type == "Chi tiÃªu theo danh má»¥c (Biá»ƒu Ä‘á»“ trÃ²n)":
        # â­ï¸ Sá»¬A Lá»–I: Chá»‰ dropna cho cÃ¡c cá»™t cáº§n thiáº¿t cho biá»ƒu Ä‘á»“ nÃ y
        df_pie = df.dropna(subset=['TOTAL', 'CATEGORY'])
        if not df_pie.empty:
            fig = px.pie(df_pie, names='CATEGORY', values='TOTAL', title='Tá»· trá»ng chi tiÃªu theo tá»«ng danh má»¥c')
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("KhÃ´ng cÃ³ Ä‘á»§ dá»¯ liá»‡u (Danh má»¥c, Tá»•ng tiá»n) Ä‘á»ƒ váº½ biá»ƒu Ä‘á»“ nÃ y.")

    elif chart_type == "Chi tiÃªu theo thá»i gian (Biá»ƒu Ä‘á»“ Ä‘Æ°á»ng)":
        # â­ï¸ Sá»¬A Lá»–I: Chá»‰ dropna cho cÃ¡c cá»™t cáº§n thiáº¿t cho biá»ƒu Ä‘á»“ nÃ y
        df_line = df.dropna(subset=['TOTAL', 'DATE'])
        if not df_line.empty:
            daily_spending = df_line.groupby(df_line['DATE'].dt.date)['TOTAL'].sum().reset_index()
            fig = px.line(daily_spending, x='DATE', y='TOTAL', title='Tá»•ng chi tiÃªu theo ngÃ y', markers=True)
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("KhÃ´ng cÃ³ Ä‘á»§ dá»¯ liá»‡u (NgÃ y, Tá»•ng tiá»n) Ä‘á»ƒ váº½ biá»ƒu Ä‘á»“ nÃ y.")
            
    elif chart_type == "Top 5 nhÃ  cung cáº¥p chi tiÃªu nhiá»u nháº¥t (Biá»ƒu Ä‘á»“ cá»™t)":
        # â­ï¸ Sá»¬A Lá»–I: Chá»‰ dropna cho cÃ¡c cá»™t cáº§n thiáº¿t cho biá»ƒu Ä‘á»“ nÃ y
        df_bar = df.dropna(subset=['TOTAL', 'COMPANY'])
        if not df_bar.empty:
            top_companies = df_bar.groupby('COMPANY')['TOTAL'].sum().nlargest(5).reset_index()
            fig = px.bar(top_companies, x='COMPANY', y='TOTAL', title='Top 5 nhÃ  cung cáº¥p cÃ³ chi tiÃªu cao nháº¥t')
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.warning("KhÃ´ng cÃ³ Ä‘á»§ dá»¯ liá»‡u (CÃ´ng ty, Tá»•ng tiá»n) Ä‘á»ƒ váº½ biá»ƒu Ä‘á»“ nÃ y.")

def page_chatbot():
    st.header("Chatbot TÆ° váº¥n TÃ i chÃ­nh")
    
    if not GEMINI_AVAILABLE:
        st.error("TÃ­nh nÄƒng nÃ y yÃªu cáº§u Google API Key. Vui lÃ²ng cáº¥u hÃ¬nh secrets Ä‘á»ƒ sá»­ dá»¥ng.")
        return

    if st.session_state.data_df.empty:
        st.warning("ChÆ°a cÃ³ dá»¯ liá»‡u chi tiÃªu Ä‘á»ƒ tÆ° váº¥n. Vui lÃ²ng táº£i hÃ³a Ä‘Æ¡n lÃªn trÆ°á»›c.")
        return

    # Khá»Ÿi táº¡o mÃ´ hÃ¬nh Gemini
    gemini_model = genai.GenerativeModel('gemini-2.5-flash')

    # Hiá»ƒn thá»‹ lá»‹ch sá»­ chat
    for role, text in st.session_state.chat_history:
        with st.chat_message(role):
            st.markdown(text)

    # Dá»¯ liá»‡u chi tiÃªu lÃ m bá»‘i cáº£nh cho bot
    data_context = st.session_state.data_df.to_string()
    
    # CÃ¡c cÃ¢u há»i gá»£i Ã½
    suggested_questions = [
        "TÃ´i Ä‘Ã£ chi tiÃªu nhiá»u nháº¥t cho danh má»¥c nÃ o?",
        "Tá»•ng chi tiÃªu cá»§a tÃ´i trong thÃ¡ng nÃ y lÃ  bao nhiÃªu?",
        "PhÃ¢n tÃ­ch xu hÆ°á»›ng chi tiÃªu cá»§a tÃ´i."
    ]
    
    st.write("---")
    st.write("Gá»£i Ã½ cho báº¡n:")
    cols = st.columns(len(suggested_questions))
    for i, question in enumerate(suggested_questions):
        if cols[i].button(question):
            st.session_state.chat_history.append(("user", question))
            with st.chat_message("user"):
                st.markdown(question)
            
            with st.chat_message("assistant"):
                with st.spinner("Bot Ä‘ang suy nghÄ©..."):
                    prompt = f"""
                    Báº¡n lÃ  má»™t trá»£ lÃ½ tÃ i chÃ­nh cÃ¡ nhÃ¢n. Dá»±a trÃªn dá»¯ liá»‡u chi tiÃªu sau Ä‘Ã¢y:
                    --- Dá»® LIá»†U ---
                    {data_context}
                    --- Háº¾T Dá»® LIá»†U ---
                    HÃ£y tráº£ lá»i cÃ¢u há»i sau cá»§a ngÆ°á»i dÃ¹ng má»™t cÃ¡ch thÃ¢n thiá»‡n vÃ  sÃºc tÃ­ch: "{question}"
                    """
                    response = gemini_model.generate_content(prompt)
                    st.markdown(response.text)
            st.session_state.chat_history.append(("assistant", response.text))
            st.rerun()


    # Nháº­n input tá»« ngÆ°á»i dÃ¹ng
    if user_prompt := st.chat_input("Báº¡n muá»‘n há»i gÃ¬ vá» chi tiÃªu cá»§a mÃ¬nh?"):
        st.session_state.chat_history.append(("user", user_prompt))
        with st.chat_message("user"):
            st.markdown(user_prompt)

        with st.chat_message("assistant"):
            with st.spinner("Bot Ä‘ang suy nghÄ©..."):
                prompt = f"""
                Báº¡n lÃ  má»™t trá»£ lÃ½ tÃ i chÃ­nh cÃ¡ nhÃ¢n. Dá»±a trÃªn dá»¯ liá»‡u chi tiÃªu sau Ä‘Ã¢y:
                --- Dá»® LIá»†U ---
                {data_context}
                --- Háº¾T Dá»® LIá»†U ---
                HÃ£y tráº£ lá»i cÃ¢u há»i sau cá»§a ngÆ°á»i dÃ¹ng má»™t cÃ¡ch thÃ¢n thiá»‡n vÃ  sÃºc tÃ­ch: "{user_prompt}"
                """
                response = gemini_model.generate_content(prompt)
                st.markdown(response.text)
        
        st.session_state.chat_history.append(("assistant", response.text))
        st.rerun()


# --- THANH SIDEBAR ÄIá»€U HÆ¯á»šNG ---

st.sidebar.title("Quáº£n lÃ½ TÃ i chÃ­nh ThÃ´ng minh")
page = st.sidebar.radio(
    "Äiá»u hÆ°á»›ng",
    ["ğŸ  Táº£i HÃ³a ÄÆ¡n", "ğŸ“Š Trá»±c Quan HÃ³a", "ğŸ—ƒï¸ Kho Dá»¯ Liá»‡u", "ğŸ¤– Chatbot TÆ° Váº¥n"]
)

if page == "ğŸ  Táº£i HÃ³a ÄÆ¡n":
    page_home()
elif page == "ğŸ“Š Trá»±c Quan HÃ³a":
    page_visualization()
elif page == "ğŸ—ƒï¸ Kho Dá»¯ Liá»‡u":
    page_data_storage()
elif page == "ğŸ¤– Chatbot TÆ° Váº¥n":
    page_chatbot()